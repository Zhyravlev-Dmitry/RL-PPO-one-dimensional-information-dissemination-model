# RL-PPO-one-dimensional-information-dissemination-model

Код был сделан как минимальный эксперимент к статье Controlling Graph Dynamics with
 Reinforcement Learning and Graph Neural Networks

1. Мы берем одномерную модель распространения информации, у каждого неориентированного ребра свой вес, вершин n=100.
2. Из равномерного распределения каждые k=20 шагов какой-то вершине приходит единица информации.
3. Каждый шаг вся информация агента дублируется его соседу с вероятностью ребра. Затем у всех информация уменьшается на a=5%.
4. RL модель на каждом шаге проверяет ровно 1 агента и узнает, сколько у него информации.
5. Цель RL модели -- найти агента, от которого идет максимум информации (или проранжировать).
